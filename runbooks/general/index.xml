<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>general on kube-prometheus runbooks</title><link>https://defenestration.github.io/runbooks/runbooks/general/</link><description>Recent content in general on kube-prometheus runbooks</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://defenestration.github.io/runbooks/runbooks/general/index.xml" rel="self" type="application/rss+xml"/><item><title>Info Inhibitor</title><link>https://defenestration.github.io/runbooks/runbooks/general/infoinhibitor/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://defenestration.github.io/runbooks/runbooks/general/infoinhibitor/</guid><description>InfoInhibitor # Meaning # This is an alert that is used to inhibit info alerts.
By themselves, the info-level alerts are sometimes very noisy, but they are relevant when combined with other alerts.
Full context More information about the alert and design considerations can be found in a kube-prometheus issue
## Impact Alert does not have any impact and it is used only as a workaround to a missing feature in alertmanager.</description></item><item><title>Node Network Interface Flapping</title><link>https://defenestration.github.io/runbooks/runbooks/general/nodenetworkinterfaceflapping/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://defenestration.github.io/runbooks/runbooks/general/nodenetworkinterfaceflapping/</guid><description>NodeNetworkInterfaceFlapping # Meaning # Network interface is often changing its status
Impact # Applications on the node may no longer be able to operate with other services. Network attached storage performance issues or even data loss.
Diagnosis # Investigate networkng issues on the node and to connected hardware. Check physical cables, check networking firewall rules and so on.
Mitigation # Cordon and drain node to migrate apps from it.</description></item><item><title>Watchdog</title><link>https://defenestration.github.io/runbooks/runbooks/general/watchdog/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://defenestration.github.io/runbooks/runbooks/general/watchdog/</guid><description>Watchdog # Meaning # This is an alert meant to ensure that the entire alerting pipeline is functional. This alert is always firing, therefore it should always be firing in Alertmanager and always fire against a receiver.
Impact # If not firing then it should alert external systems that this alerting system is no longer working.
Diagnosis # Misconfigured alertmanager, bad credentials, bad endpoint, firewalls.. Check alertmanager logs.
Mitigation # There are integrations with various notification mechanisms that send a notification when this alert is not firing.</description></item><item><title/><link>https://defenestration.github.io/runbooks/runbooks/general/targetdown/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://defenestration.github.io/runbooks/runbooks/general/targetdown/</guid><description>TargetDown # Meaning # The alert means that one or more prometheus scrape targets are down. It fires when at least 10% of scrape targets in a Service are unreachable.
Full context Prometheus works by sending an HTTP GET request to all of its &amp;ldquo;targets&amp;rdquo; every few seconds. So TargetDown really means that Prometheus just can&amp;rsquo;t access your service, which may or may not mean it&amp;rsquo;s actually down. If your service appears to be running fine, a common cause could be a misconfigured ServiceMonitor (maybe the port or path is incorrect), a misconfigured NetworkPolicy, or Service with incorrect labelSelectors that isn&amp;rsquo;t selecting any Pods.</description></item></channel></rss>