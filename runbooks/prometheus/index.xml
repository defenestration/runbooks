<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>prometheus on kube-prometheus runbooks</title><link>https://defenestration.github.io/runbooks/runbooks/prometheus/</link><description>Recent content in prometheus on kube-prometheus runbooks</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://defenestration.github.io/runbooks/runbooks/prometheus/index.xml" rel="self" type="application/rss+xml"/><item><title/><link>https://defenestration.github.io/runbooks/runbooks/prometheus/prometheusbadconfig/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://defenestration.github.io/runbooks/runbooks/prometheus/prometheusbadconfig/</guid><description>PrometheusBadConfig # Meaning # Alert fires when Prometheus cannot successfully reload the configuration file due to the file having incorrect content.
Impact # Configuration cannot be reloaded and prometheus operates with last known good configuration. Configuration changes in any of Prometheus, Probe, PodMonitor, or ServiceMonitor objects may not be picked up by prometheus server.
Diagnosis # Check prometheus container logs for an explanation of which part of the configuration is problematic.</description></item><item><title/><link>https://defenestration.github.io/runbooks/runbooks/prometheus/prometheusduplicatetimestamps/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://defenestration.github.io/runbooks/runbooks/prometheus/prometheusduplicatetimestamps/</guid><description>PrometheusDuplicateTimestamps # Find the Prometheus Pod that concerns this.
$ kubectl -n &amp;lt;namespace&amp;gt; get pod prometheus-k8s-0 2/2 Running 1 122m prometheus-k8s-1 2/2 Running 1 122m Look at the logs of each of them, there should be a log line such as:
$ kubectl -n &amp;lt;namespace&amp;gt; logs prometheus-k8s-0 level=warn ts=2021-01-04T15:08:55.613Z caller=scrape.go:1372 component=&amp;#34;scrape manager&amp;#34; scrape_pool=default/main-ingress-nginx-controller/0 target=http://10.0.7.3:10254/metrics msg=&amp;#34;Error on ingesting samples with different value but same timestamp&amp;#34; num_dropped=16 Now there is a judgement call to make, this could be the result of:</description></item><item><title/><link>https://defenestration.github.io/runbooks/runbooks/prometheus/prometheusoutofordertimestamps/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://defenestration.github.io/runbooks/runbooks/prometheus/prometheusoutofordertimestamps/</guid><description>PrometheusOutOfOrderTimestamps # More information in https://www.robustperception.io/debugging-out-of-order-samples</description></item><item><title/><link>https://defenestration.github.io/runbooks/runbooks/prometheus/prometheusrulefailures/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://defenestration.github.io/runbooks/runbooks/prometheus/prometheusrulefailures/</guid><description>PrometheusRuleFailures # Your best starting point is the rules page of the Prometheus UI (:9090/rules). It will show the error.
You can also evaluate the rule expression yourself, using the UI, or maybe using PromLens to help debug expression issues.</description></item><item><title/><link>https://defenestration.github.io/runbooks/runbooks/prometheus/prometheustargetsyncfailure/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://defenestration.github.io/runbooks/runbooks/prometheus/prometheustargetsyncfailure/</guid><description>PrometheusTargetSyncFailure # Meaning # This alert is triggered when at least one of the Prometheus instances has consistently failed to sync its configuration.
Impact # Metrics and alerts may be missing or inaccurate.
Diagnosis # Determine whether the alert is for the cluster or user workload Prometheus by inspecting the alert&amp;rsquo;s namespace label.
Check the logs for the appropriate Prometheus instance:
$ NAMESPACE=&amp;#39;&amp;lt;value of namespace label from alert&amp;gt;&amp;#39; $ oc -n $NAMESPACE logs -l &amp;#39;app=prometheus&amp;#39; level=error .</description></item></channel></rss>